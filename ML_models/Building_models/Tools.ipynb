{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project name: DJ-Running\n",
    "\n",
    "Authors: Jorge García de Quirós, Sandra Baldassarri, Pedro Álvarez\n",
    "\n",
    "Affiliation/Institution: Computer Science and Systems Engineering Department, University of Zaragoza (Spain)\n",
    "\n",
    "Paper: RIADA: a machine-learning based infrastructure for recognising the emotions of the Spotify songs\n",
    "\n",
    "Date: October, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_selection_aprox: array of sckitlearn feature selectors\n",
    "# X: Features of the dataset\n",
    "# y: Labels of the dataset\n",
    "# features: names of the features for each X column \n",
    "# returns sorted array in increment order of the importance of each feature\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "def findWorstFeatures (feature_selection_aprox, X, y, features):\n",
    "    #vector where the total appearances will be saved\n",
    "    ranker = [0]*len(X[0])\n",
    "    for aprox in feature_selection_aprox:\n",
    "        for q_feat in range (1,len(X[0])):\n",
    "            KB = SelectKBest(aprox, k=q_feat)\n",
    "            KB.fit(X, y)\n",
    "            ranker=ranker+KB.get_support() #Vector donde 1 si es seleccionado y 0 si no\n",
    "    return [a for _,a in sorted(zip(ranker,features))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, features, model, score):\n",
    "        self.features = features\n",
    "        self.model = model\n",
    "        self.score = score\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Features: \" + str(self.features) +  \"\\nModel: \" + str(self.model)  + \"\\nScore: \" + str(self._score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_frame: pandas data frame\n",
    "#models: [[model, hyper], [model2, hyper2]]\n",
    "#feature_selection: [fs1, fs2, ...]\n",
    "#min_var: minimum quantity of variable\n",
    "#max_var: maximum quantity of variable\n",
    "#treshold: treshold considered to binarise the label\n",
    "#target: name of the column target of the model\n",
    "#niter: num of iterarions in randomized search for hyperparams\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "def findBestModel(data_frame, models, feature_selection_methods, min_var, max_var, target, niter):\n",
    "    #Results array for each model\n",
    "    bestResults = []\n",
    "    for model in models:\n",
    "        bestResults.append(Model(None,None,0))\n",
    "    \n",
    "    #Initialize arrays\n",
    "    X = (data_frame.loc[:, data_frame.columns[0:len(data_frame.columns)-1]]).values\n",
    "    Y = data_frame.loc[:, target:target].dropna()\n",
    "    \n",
    "    #Feature names array ordered (min-max) in features inmportance\n",
    "    worst_features = findWorstFeatures(feature_selection_methods, X, Y, data_frame.columns[0:len(data_frame.columns)-1])\n",
    "    \n",
    "    i=0\n",
    "    for model in models:\n",
    "        for drop_vars in range(len(X[0])-max_var,len(X[0])-min_var,):\n",
    "            #drop_vars worst features dropped\n",
    "            \n",
    "            df_aux = data_frame.loc[:, data_frame.columns[0:len(data_frame.columns)-1]]\n",
    "            \n",
    "            new_X = df_aux.drop(worst_features[0:drop_vars], axis=1)\n",
    "\n",
    "            X_train = new_X \n",
    "            y_train = Y\n",
    "\n",
    "            random_search = RandomizedSearchCV(model[0], param_distributions=model[1], n_iter=niter, cv=3, random_state=0, scoring=\"f1_macro\")\n",
    "            random_search.fit(X_train, y_train)\n",
    "            score = random_search.best_score_\n",
    "\n",
    "            if ((bestResults[i].model is None) or  score > bestResults[i].score):\n",
    "                    bestResults[i] = Model(worst_features[drop_vars: len(data_frame.columns)-1], random_search.best_estimator_ , score) \n",
    "        i = i+1\n",
    "    return bestResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,accuracy_score\n",
    "\n",
    "def printResults(results, X_train, X_test, y_train, y_test):\n",
    "    for result in results:\n",
    "        print \"--------------------------------------------------------------------\"\n",
    "        print str(result.model)\n",
    "        print \"Features:\" + str(result.features)\n",
    "        result.model.fit(X_train.loc[:, result.features], y_train)\n",
    "        y_pred = result.model.predict(X_test.loc[:, result.features])\n",
    "        print (\"F1_test: %0.4f\") % (f1_score(y_test, y_pred, average=\"macro\"))\n",
    "        print (\"F1_train: %0.4f\") % (result.score)\n",
    "        print (\"Precision: %0.4f\") % (precision_score(y_test, y_pred, average=\"macro\"))\n",
    "        print (\"Recall: %0.4f\") % recall_score(y_test, y_pred, average=\"macro\")\n",
    "        print (\"Accuracy: %0.4f\") % accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "def saveModels (results, folder, name):\n",
    "    for result in results:\n",
    "        dump(result.model, folder+'/model_'+name+'_'+result.model.__class__.__name__+'.joblib')\n",
    "        dump(result.features, folder+'/features_'+name+'_'+result.model.__class__.__name__+'.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "def loadModels (folder, names):\n",
    "    models = {}\n",
    "    for name in names:\n",
    "        models[name] = [load(folder+\"model_\"+name+\".joblib\"), load(folder+\"features_\"+name+\".joblib\")]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printComparation(model, features, X, y):\n",
    "        y_pred = model.predict(X.loc[:, features])\n",
    "        print (\"F1_test: %0.4f\") % (f1_score(y, y_pred, average=\"macro\"))\n",
    "        print (\"Precision: %0.4f\") % (precision_score(y, y_pred, average=\"macro\"))\n",
    "        print (\"Recall: %0.4f\") % recall_score(y, y_pred, average=\"macro\")\n",
    "        print (\"Accuracy: %0.4f\") % accuracy_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculateLabel([\"SA_GE_happy_RandomForestClassifier\",\"SA_GE_sad_RandomForestClassifier\"],\n",
    "#\"/home/jorge/djrunning/experimentos_py/best_mood_classifier/1v3/\",'/home/jorge/djrunning/datasets/new_dataset/mf_big_2.csv',\n",
    "#'/home/jorge/djrunning/datasets/new_dataset/mf_big_2.csv')\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "    \n",
    "def calculateLabel(model_names, url, url_dataset, url_normalization):\n",
    "    #Set normalizer\n",
    "    o_model = pd.read_csv(url_normalization)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    aux_X = min_max_scaler.fit(o_model.loc[:,'valence':'mode'])\n",
    "    \n",
    "    #Import dataset\n",
    "    dataset = pd.read_csv(url_dataset)\n",
    "    aux_X = min_max_scaler.transform(dataset.loc[:,'valence':'mode'])\n",
    "    dataset_norm=pd.DataFrame(aux_X)\n",
    "    dataset_norm.columns=[u'valence', u'energy', u'liveness', u'tempo', u'speechiness',\n",
    "       u'acousticness', u'instrumentalness', u'danceability', u'key',\n",
    "       u'duration_ms', u'loudness', u'mode']\n",
    "\n",
    "    models = loadModels (url, model_names)\n",
    "    y_pred = []\n",
    "    new_names = []\n",
    "    for model_name in models:\n",
    "        model,features = models[model_name]\n",
    "        y_pred.append(model.predict_proba(dataset_norm.loc[:, features])[:,1])\n",
    "        new_names.append(model_name)\n",
    "        \n",
    "\n",
    "    y_pred = np.matrix(y_pred)\n",
    "    resul = pd.DataFrame(np.transpose(y_pred))\n",
    "    resul.columns = new_names\n",
    "    \n",
    "    return resul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "def search_feat_df(df,features):\n",
    "    new_df = pd.DataFrame()\n",
    "    songs_50 = []\n",
    "    for index, row in df.iterrows():\n",
    "        songs_50.append(row['id'])\n",
    "        if len(songs_50) == 50:\n",
    "            tracks_features = SP.audio_features(songs_50)\n",
    "            tracks_features  = list(filter(None, tracks_features))\n",
    "            aux = pd.DataFrame(tracks_features)\n",
    "            new_df = new_df.append(aux[features])\n",
    "            songs_50 = []\n",
    "\n",
    "    if (len(songs_50)>0):\n",
    "        tracks_features = SP.audio_features(songs_50)\n",
    "        tracks_features  = list(filter(None, tracks_features))\n",
    "        aux = pd.DataFrame(tracks_features)\n",
    "        new_df = new_df.append(aux[features])\n",
    "        songs_50 = []\n",
    "    return new_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
